{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26ab475a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3101cca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(torch.nn.Module):\n",
    "    def __init__(self,hidden_dim,embedding_dim, vocab_size):\n",
    "        super().__init__()\n",
    "        self.input_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding = torch.nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim)\n",
    "\n",
    "\n",
    "        self.Ui = torch.nn.Parameter(torch.Tensor(embedding_dim,hidden_dim))\n",
    "        self.Vi = torch.nn.Parameter(torch.Tensor(hidden_dim,hidden_dim))\n",
    "        self.bi = torch.nn.Parameter(torch.Tensor(hidden_dim))\n",
    "\n",
    "        self.Uf = torch.nn.Parameter(torch.Tensor(embedding_dim,hidden_dim))\n",
    "        self.Vf = torch.nn.Parameter(torch.Tensor(hidden_dim, hidden_dim))\n",
    "        self.bf = torch.nn.Parameter(torch.Tensor(hidden_dim))\n",
    "\n",
    "        self.Uc = torch.nn.Parameter(torch.Tensor(embedding_dim,hidden_dim))\n",
    "        self.Vc = torch.nn.Parameter(torch.Tensor(hidden_dim, hidden_dim))\n",
    "        self.bc = torch.nn.Parameter(torch.Tensor(hidden_dim))\n",
    "\n",
    "        self.Uo = torch.nn.Parameter(torch.Tensor(embedding_dim,hidden_dim))\n",
    "        self.Vo = torch.nn.Parameter(torch.Tensor(hidden_dim, hidden_dim))\n",
    "        self.bo = torch.nn.Parameter(torch.Tensor(hidden_dim))\n",
    "\n",
    "        self.linear = torch.nn.Linear(hidden_dim, 2)\n",
    "\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        stdv = 1.0 / math.sqrt(self.hidden_dim)\n",
    "        for weight in self.parameters():\n",
    "            weight.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, x, init_states=None):\n",
    "        bs, seq_sz = x.size()\n",
    "        hidden_seq = []\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        if init_states is None:\n",
    "            h_t, c_t = (\n",
    "                torch.zeros(bs, self.hidden_size).to(x.device),\n",
    "                torch.zeros(bs, self.hidden_size).to(x.device),\n",
    "            )\n",
    "        else:\n",
    "            h_t, c_t = init_states\n",
    "\n",
    "        for t in range(seq_sz):\n",
    "            x_t = x[:,t,:]\n",
    "\n",
    "            i_t = torch.sigmoid(x_t @ self.Ui + h_t @ self.Vi + self.bi)\n",
    "            f_t = torch.sigmoid(x_t @ self.Uf + h_t @ self.Vf + self.bf)\n",
    "            o_t = torch.sigmoid(x_t @ self.Uo + h_t @ self.Vo + self.bo)\n",
    "            g_t = torch.tanh(x_t @ self.Uc + h_t @ self.Vc + self.bc)\n",
    "\n",
    "            c_t = f_t * c_t + i_t * g_t \n",
    "            h_t = o_t * torch.tanh(c_t )\n",
    "\n",
    "            hidden_seq.append(h_t.unsqueeze(0))\n",
    "\n",
    "        hidden_seq = torch.cat(hidden_seq, dim = 0)\n",
    "        hidden_seq = hidden_seq.transpose(0, 1).contiguous()\n",
    "        logits = self.linear(h_t)  # last timestep hidden state\n",
    "\n",
    "        return logits, hidden_seq, (h_t, c_t)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96aa80a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "from torchtext.experimental.datasets import IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49801aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:15<00:00, 5.60MB/s]\n",
      "25000lines [00:02, 9444.15lines/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Make sure download directory exists\n",
    "os.makedirs(\".data\", exist_ok=True)\n",
    "\n",
    "from torchtext.experimental.datasets import IMDB\n",
    "\n",
    "train_dataset, test_dataset = IMDB(root=\".data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62328208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 25000\n",
      "Test size: 25000\n",
      "Example: (tensor(0), tensor([   13,  1568,    13,   246, 35468,    43,    64,   398,  1135,    92,\n",
      "            7,    37,     2,  7126,    15,  3363,    11,    60,    11,    17,\n",
      "           94,   629,    12,  6921,     3,    13,    87,   553,    15,    38,\n",
      "           94,    11,    17, 20193,    40,  1225,     3,    16,     3,  9263,\n",
      "           51,    11,   131,   780,     8,  2480,    14,   682,     4,  1575,\n",
      "          118,     6,   342,     7,   114,  1160,  3052,    13,    72,    75,\n",
      "            8,    74,    14,    19,   537,     3,     2,   121,    10,  5959,\n",
      "          194,     6,   191,  3862,   474,  1424,   766,  4314,    42,   489,\n",
      "            8,   834,   287,    61,    58,    50,   127,     3,    12,   826,\n",
      "           61,   489,     8,  1132,    47, 11859,     8,   257,    56,   441,\n",
      "            7,   669,    28,    54,     2,   863, 29737,   209,    50,   781,\n",
      "         1001,  1304,   147,    18,     2,  2675,   337,     5,  1510,  1304,\n",
      "           12,     2,  2359,  1592,     3,    12,   203,  2182,  7271,     5,\n",
      "         1919, 19586,     7, 21478,    50,    73,  4656,    28,  2381,     4,\n",
      "           61,    52,   402,    20,    47,   474,  1692,     4,  8135,     4,\n",
      "            5,   999,   347,     3,    54,  1080,    78,    50,    13,   246,\n",
      "        35468,    10,    15,  1614,   161,   587,     4,    14,    17,  1160,\n",
      "         8206,     3,    72,     4,     2,   402,     5,  1000,   145,    31,\n",
      "          175,     5,   242,   203,     4,    63,   101,    11,     9,    16,\n",
      "           29,   330,    45,    56,  6655,   100,  4461,     3,   143,    64,\n",
      "        23465,   348,   172,    11,  1574,     4,    12,   635,   402,     5,\n",
      "         1000,    31,     6,   663, 10198,    12,  3862,   437,     3,    63,\n",
      "        14516,  4441,     4,  4634,    73,  1476,     8,    57,   176,   435,\n",
      "          304,  1721,     4,    75,   402,   145,    12,    32,   114,     3,\n",
      "           13,    91, 12612,     2,  1023,    19,     2,   198,    15,   107,\n",
      "          402,   608,    12,     2,    23,    10,   608,    19,  1577,  5042,\n",
      "          251,    79,    49,     8,  1498,    85,     5,   105,   280,     8,\n",
      "           34,   608,    12,  8206,  2181,    12,   835,     3,    13,   246,\n",
      "        35468,    10,     6,    57,    23,    19,   256,  1752,     8,  2058,\n",
      "            2,  3751,     5, 18993,    25,    65,  5230,  1400,    24,     7,\n",
      "         3862,   437,     3,    22,    72,     4,    14,    23,   159,     9,\n",
      "           27,    33,    81,     7,     6,   121,     3]))\n"
     ]
    }
   ],
   "source": [
    "train_list = list(train_dataset)\n",
    "test_list = list(test_dataset)\n",
    "\n",
    "print(\"Train size:\", len(train_list))\n",
    "print(\"Test size:\", len(test_list))\n",
    "print(\"Example:\", train_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd91f3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 20000\n",
      "Validation size: 5000\n"
     ]
    }
   ],
   "source": [
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "\n",
    "train_data, val_data = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "print(\"Train size:\", len(train_data))\n",
    "print(\"Validation size:\", len(val_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ad57f1b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected Tensor as element 0 in argument 0, but got tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pad_sequence\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m train_dataset = \u001b[43mpad_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_value\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m test_dataset = pad_sequence(test_dataset, batch_first = \u001b[38;5;28;01mTrue\u001b[39;00m, padding_value=\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/utils/rnn.py:482\u001b[39m, in \u001b[36mpad_sequence\u001b[39m\u001b[34m(sequences, batch_first, padding_value, padding_side)\u001b[39m\n\u001b[32m    478\u001b[39m         sequences = sequences.unbind(\u001b[32m0\u001b[39m)  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[32m    480\u001b[39m \u001b[38;5;66;03m# assuming trailing dimensions and type of all the Tensors\u001b[39;00m\n\u001b[32m    481\u001b[39m \u001b[38;5;66;03m# in sequences are same and fetching those from sequences[0]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m482\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_nn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpad_sequence\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m    \u001b[49m\u001b[43msequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m    484\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpadding_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m    487\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: expected Tensor as element 0 in argument 0, but got tuple"
     ]
    }
   ],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "train_dataset = pad_sequence(train_dataset, batch_first=True, padding_value=0)\n",
    "test_dataset = pad_sequence(test_dataset, batch_first = True, padding_value=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5749421",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
